{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zqrc0\\AppData\\Local\\Temp\\ipykernel_25376\\615981568.py:190: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  coarse_generator.load_state_dict(torch.load(best_coarse_path, map_location=device))\n",
      "C:\\Users\\zqrc0\\AppData\\Local\\Temp\\ipykernel_25376\\615981568.py:191: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  fine_generator.load_state_dict(torch.load(best_fine_path,   map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] TEST_000.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_000.png\n",
      "[INFO] TEST_001.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_001.png\n",
      "[INFO] TEST_002.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_002.png\n",
      "[INFO] TEST_003.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_003.png\n",
      "[INFO] TEST_004.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_004.png\n",
      "[INFO] TEST_005.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_005.png\n",
      "[INFO] TEST_006.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_006.png\n",
      "[INFO] TEST_007.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_007.png\n",
      "[INFO] TEST_008.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_008.png\n",
      "[INFO] TEST_009.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_009.png\n",
      "[INFO] TEST_010.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_010.png\n",
      "[INFO] TEST_011.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_011.png\n",
      "[INFO] TEST_012.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_012.png\n",
      "[INFO] TEST_013.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_013.png\n",
      "[INFO] TEST_014.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_014.png\n",
      "[INFO] TEST_015.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_015.png\n",
      "[INFO] TEST_016.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_016.png\n",
      "[INFO] TEST_017.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_017.png\n",
      "[INFO] TEST_018.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_018.png\n",
      "[INFO] TEST_019.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_019.png\n",
      "[INFO] TEST_020.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_020.png\n",
      "[INFO] TEST_021.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_021.png\n",
      "[INFO] TEST_022.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_022.png\n",
      "[INFO] TEST_023.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_023.png\n",
      "[INFO] TEST_024.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_024.png\n",
      "[INFO] TEST_025.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_025.png\n",
      "[INFO] TEST_026.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_026.png\n",
      "[INFO] TEST_027.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_027.png\n",
      "[INFO] TEST_028.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_028.png\n",
      "[INFO] TEST_029.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_029.png\n",
      "[INFO] TEST_030.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_030.png\n",
      "[INFO] TEST_031.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_031.png\n",
      "[INFO] TEST_032.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_032.png\n",
      "[INFO] TEST_033.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_033.png\n",
      "[INFO] TEST_034.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_034.png\n",
      "[INFO] TEST_035.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_035.png\n",
      "[INFO] TEST_036.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_036.png\n",
      "[INFO] TEST_037.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_037.png\n",
      "[INFO] TEST_038.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_038.png\n",
      "[INFO] TEST_039.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_039.png\n",
      "[INFO] TEST_040.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_040.png\n",
      "[INFO] TEST_041.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_041.png\n",
      "[INFO] TEST_042.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_042.png\n",
      "[INFO] TEST_043.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_043.png\n",
      "[INFO] TEST_044.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_044.png\n",
      "[INFO] TEST_045.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_045.png\n",
      "[INFO] TEST_046.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_046.png\n",
      "[INFO] TEST_047.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_047.png\n",
      "[INFO] TEST_048.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_048.png\n",
      "[INFO] TEST_049.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_049.png\n",
      "[INFO] TEST_050.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_050.png\n",
      "[INFO] TEST_051.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_051.png\n",
      "[INFO] TEST_052.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_052.png\n",
      "[INFO] TEST_053.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_053.png\n",
      "[INFO] TEST_054.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_054.png\n",
      "[INFO] TEST_055.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_055.png\n",
      "[INFO] TEST_056.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_056.png\n",
      "[INFO] TEST_057.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_057.png\n",
      "[INFO] TEST_058.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_058.png\n",
      "[INFO] TEST_059.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_059.png\n",
      "[INFO] TEST_060.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_060.png\n",
      "[INFO] TEST_061.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_061.png\n",
      "[INFO] TEST_062.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_062.png\n",
      "[INFO] TEST_063.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_063.png\n",
      "[INFO] TEST_064.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_064.png\n",
      "[INFO] TEST_065.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_065.png\n",
      "[INFO] TEST_066.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_066.png\n",
      "[INFO] TEST_067.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_067.png\n",
      "[INFO] TEST_068.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_068.png\n",
      "[INFO] TEST_069.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_069.png\n",
      "[INFO] TEST_070.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_070.png\n",
      "[INFO] TEST_071.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_071.png\n",
      "[INFO] TEST_072.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_072.png\n",
      "[INFO] TEST_073.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_073.png\n",
      "[INFO] TEST_074.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_074.png\n",
      "[INFO] TEST_075.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_075.png\n",
      "[INFO] TEST_076.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_076.png\n",
      "[INFO] TEST_077.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_077.png\n",
      "[INFO] TEST_078.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_078.png\n",
      "[INFO] TEST_079.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_079.png\n",
      "[INFO] TEST_080.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_080.png\n",
      "[INFO] TEST_081.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_081.png\n",
      "[INFO] TEST_082.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_082.png\n",
      "[INFO] TEST_083.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_083.png\n",
      "[INFO] TEST_084.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_084.png\n",
      "[INFO] TEST_085.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_085.png\n",
      "[INFO] TEST_086.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_086.png\n",
      "[INFO] TEST_087.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_087.png\n",
      "[INFO] TEST_088.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_088.png\n",
      "[INFO] TEST_089.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_089.png\n",
      "[INFO] TEST_090.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_090.png\n",
      "[INFO] TEST_091.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_091.png\n",
      "[INFO] TEST_092.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_092.png\n",
      "[INFO] TEST_093.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_093.png\n",
      "[INFO] TEST_094.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_094.png\n",
      "[INFO] TEST_095.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_095.png\n",
      "[INFO] TEST_096.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_096.png\n",
      "[INFO] TEST_097.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_097.png\n",
      "[INFO] TEST_098.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_098.png\n",
      "[INFO] TEST_099.png 복원 완료(마스크 팽창 적용) -> data/output_colToper_2025010602\\TEST_099.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "############################\n",
    "# (1) 모델 구조 정의 (학습시 사용한 Stage1Generator, Stage2Generator)\n",
    "############################\n",
    "\n",
    "class GatedConv2d(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, activation=torch.nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.feature_conv = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.mask_conv    = torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.sigmoid      = torch.nn.Sigmoid()\n",
    "        self.activation   = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.feature_conv(x)\n",
    "        m = self.mask_conv(x)\n",
    "        gated = self.sigmoid(m)\n",
    "        if self.activation is not None:\n",
    "            f = self.activation(f)\n",
    "        return f * gated\n",
    "\n",
    "class GatedDeconv2d(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=4, stride=2, padding=1, activation=torch.nn.ReLU()):\n",
    "        super().__init__()\n",
    "        self.feature_deconv = torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.mask_deconv    = torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.sigmoid        = torch.nn.Sigmoid()\n",
    "        self.activation     = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        f = self.feature_deconv(x)\n",
    "        m = self.mask_deconv(x)\n",
    "        gated = self.sigmoid(m)\n",
    "        if self.activation is not None:\n",
    "            f = self.activation(f)\n",
    "        return f * gated\n",
    "\n",
    "class ContextualAttention(torch.nn.Module):\n",
    "    def __init__(self, kernel_size=3, stride=1, dilation=1):\n",
    "        super().__init__()\n",
    "        self.conv = torch.nn.Conv2d(512, 512, kernel_size, stride, dilation, bias=False)\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,C,H,W = x.size()\n",
    "        query = x.view(B,C,-1)\n",
    "        key   = x.view(B,C,-1)\n",
    "        value = x.view(B,C,-1)\n",
    "\n",
    "        attn = torch.bmm(query.permute(0,2,1), key)  # (B,H*W,C) x (B,C,H*W)\n",
    "        attn = self.softmax(attn)\n",
    "        out  = torch.bmm(attn, value.permute(0,2,1))\n",
    "        out  = out.permute(0,2,1).view(B,C,H,W)\n",
    "        out  = self.conv(out)\n",
    "        return out\n",
    "\n",
    "class Stage1Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # ----- Encoder (Down) -----\n",
    "        self.enc1 = GatedConv2d(4,   64, 4, 2, 1)\n",
    "        self.enc2 = GatedConv2d(64,  128,4, 2, 1)\n",
    "        self.enc3 = GatedConv2d(128, 256,4, 2, 1)\n",
    "        self.enc4 = GatedConv2d(256, 512,4, 2, 1)\n",
    "\n",
    "        # ----- Decoder (Up) -----\n",
    "        self.dec1_up   = GatedDeconv2d(512,256,4,2,1)\n",
    "        self.dec1_conv = GatedConv2d(256+256,256,3,1,1)\n",
    "\n",
    "        self.dec2_up   = GatedDeconv2d(256,128,4,2,1)\n",
    "        self.dec2_conv = GatedConv2d(128+128,128,3,1,1)\n",
    "\n",
    "        self.dec3_up   = GatedDeconv2d(128,64,4,2,1)\n",
    "        self.dec3_conv = GatedConv2d(64+64,64,3,1,1)\n",
    "\n",
    "        self.dec4_up   = GatedDeconv2d(64,64,4,2,1)\n",
    "        self.dec4_conv = torch.nn.Conv2d(64,3,3,1,1)\n",
    "        self.final_act = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # x: (N,3,H,W), mask: (N,1,H,W)\n",
    "        inp = torch.cat((x, mask), dim=1)   # (N,4,H,W)\n",
    "        e1 = self.enc1(inp)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "\n",
    "        d1_up = self.dec1_up(e4)\n",
    "        d1_in = torch.cat([d1_up, e3], dim=1)\n",
    "        d1    = self.dec1_conv(d1_in)\n",
    "\n",
    "        d2_up = self.dec2_up(d1)\n",
    "        d2_in = torch.cat([d2_up, e2], dim=1)\n",
    "        d2    = self.dec2_conv(d2_in)\n",
    "\n",
    "        d3_up = self.dec3_up(d2)\n",
    "        d3_in = torch.cat([d3_up, e1], dim=1)\n",
    "        d3    = self.dec3_conv(d3_in)\n",
    "\n",
    "        d4_up = self.dec4_up(d3)\n",
    "        d4    = self.dec4_conv(d4_up)\n",
    "        out   = self.final_act(d4)\n",
    "        return out\n",
    "\n",
    "class Stage2Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # ----- Encoder -----\n",
    "        self.enc1 = GatedConv2d(7,   64, 4, 2, 1)\n",
    "        self.enc2 = GatedConv2d(64,  128,4, 2, 1)\n",
    "        self.enc3 = GatedConv2d(128, 256,4, 2, 1)\n",
    "        self.enc4 = GatedConv2d(256, 512,4, 2, 1)\n",
    "\n",
    "        # Contextual Attention\n",
    "        self.contextual_attention = ContextualAttention()\n",
    "\n",
    "        # ----- Decoder (U-Net) -----\n",
    "        self.dec1_up   = GatedDeconv2d(512,256,4,2,1)\n",
    "        self.dec1_conv = GatedConv2d(256 + 256, 256, 3,1,1)\n",
    "\n",
    "        self.dec2_up   = GatedDeconv2d(256,128,4,2,1)\n",
    "        self.dec2_conv = GatedConv2d(128 + 128, 128, 3,1,1)\n",
    "\n",
    "        self.dec3_up   = GatedDeconv2d(128,64,4,2,1)\n",
    "        self.dec3_conv = GatedConv2d(64 + 64, 64, 3,1,1)\n",
    "\n",
    "        self.dec4_up   = GatedDeconv2d(64,64,4,2,1)\n",
    "        self.dec4_conv = torch.nn.Conv2d(64,3,3,1,1)\n",
    "        self.final_act = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, coarse_out, inp, mask):\n",
    "        # coarse_out: (N,3,H,W), inp: (N,3,H,W), mask: (N,1,H,W)\n",
    "        fin_inp = torch.cat((coarse_out, inp, mask), dim=1)  # (N,7,H,W)\n",
    "\n",
    "        e1 = self.enc1(fin_inp)\n",
    "        e2 = self.enc2(e1)\n",
    "        e3 = self.enc3(e2)\n",
    "        e4 = self.enc4(e3)\n",
    "\n",
    "        e4_attn = self.contextual_attention(e4)\n",
    "\n",
    "        d1_up = self.dec1_up(e4_attn)\n",
    "        d1_in = torch.cat([d1_up, e3], dim=1)\n",
    "        d1    = self.dec1_conv(d1_in)\n",
    "\n",
    "        d2_up = self.dec2_up(d1)\n",
    "        d2_in = torch.cat([d2_up, e2], dim=1)\n",
    "        d2    = self.dec2_conv(d2_in)\n",
    "\n",
    "        d3_up = self.dec3_up(d2)\n",
    "        d3_in = torch.cat([d3_up, e1], dim=1)\n",
    "        d3    = self.dec3_conv(d3_in)\n",
    "\n",
    "        d4_up = self.dec4_up(d3)\n",
    "        d4    = self.dec4_conv(d4_up)\n",
    "        out   = self.final_act(d4)\n",
    "        return out\n",
    "\n",
    "\n",
    "############################\n",
    "# (2) 가중치 경로 (학습코드에서 만든 best_coarse_generator, best_fine_generator)\n",
    "############################\n",
    "best_coarse_path = \"model/09/coarse_generator_epoch51.pth\"\n",
    "best_fine_path   = \"model/09/fine_generator_epoch51.pth\"\n",
    "\n",
    "############################\n",
    "# (3) 테스트 이미지 폴더 및 마스크 폴더\n",
    "############################\n",
    "test_input_dir = \"../02_color/data/output_grayTocol_2025010602\"\n",
    "test_mask_dir  = \"../data/output_01_mask\"\n",
    "output_dir     = \"data/output_colToper_2025010602\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "############################\n",
    "# (4) 모델 불러오기\n",
    "############################\n",
    "coarse_generator = Stage1Generator().to(device)\n",
    "fine_generator   = Stage2Generator().to(device)\n",
    "\n",
    "# 학습된 가중치 로드\n",
    "coarse_generator.load_state_dict(torch.load(best_coarse_path, map_location=device))\n",
    "fine_generator.load_state_dict(torch.load(best_fine_path,   map_location=device))\n",
    "\n",
    "coarse_generator.eval()\n",
    "fine_generator.eval()\n",
    "\n",
    "############################\n",
    "# (5) 테스트용 transform\n",
    "############################\n",
    "transform = T.Compose([\n",
    "    T.Resize((512,512)),  # 학습 시와 동일한 해상도\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "############################\n",
    "# (6) 테스트 진행 (마스크 확장 적용 + 최종 원본마스크 반영)\n",
    "############################\n",
    "test_files = [f for f in os.listdir(test_input_dir) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for filename in test_files:\n",
    "        input_path = os.path.join(test_input_dir, filename)\n",
    "        mask_path  = os.path.join(test_mask_dir, filename)\n",
    "\n",
    "        if not os.path.exists(mask_path):\n",
    "            print(f\"[WARNING] {mask_path}가 존재하지 않아 스킵합니다.\")\n",
    "            continue\n",
    "\n",
    "        # (6-1) 이미지 로드\n",
    "        inp_img  = Image.open(input_path).convert(\"RGB\")\n",
    "        mask_img = Image.open(mask_path).convert(\"L\")\n",
    "\n",
    "        # (6-1') 원본 마스크도 별도 보관(최종 후처리에 사용)\n",
    "        original_mask_img = mask_img.copy()  # 복사해둬야 dilation 전에 보존\n",
    "\n",
    "        # (6-2) 마스크 확장(팽창, dilation) 예시\n",
    "        mask_np = np.array(mask_img, dtype=np.uint8)\n",
    "        kernel = np.ones((3,3), np.uint8)  # 커널 크기를 조절(3x3,5x5 등)하면 확장 범위가 달라집니다\n",
    "        dilated_mask = cv2.dilate(mask_np, kernel, iterations=2)  # 1~2 정도면 살짝 확장\n",
    "\n",
    "        # dilated_mask -> 다시 PIL\n",
    "        expanded_mask_img = Image.fromarray(dilated_mask)\n",
    "\n",
    "        # (6-3) transform -> Tensor\n",
    "        inp_tensor        = transform(inp_img).unsqueeze(0).to(device)          # (1,3,H,W)\n",
    "        expanded_mask_ten = transform(expanded_mask_img).unsqueeze(0).to(device)# (1,1,H,W)\n",
    "        original_mask_ten = transform(original_mask_img).unsqueeze(0).to(device)# (1,1,H,W)\n",
    "\n",
    "        # (6-4) 손상 영역 0 처리(확장된 마스크)\n",
    "        expanded_mask_bc  = expanded_mask_ten.expand_as(inp_tensor)             # (1,3,H,W)\n",
    "        damaged_inp       = inp_tensor * (1 - expanded_mask_bc)\n",
    "\n",
    "        # (6-5) Stage1 (Coarse) - 확장 마스크 기준\n",
    "        coarse_out = coarse_generator(damaged_inp, expanded_mask_ten)\n",
    "\n",
    "        # (6-6) Stage2 (Fine) - 확장 마스크 기준\n",
    "        fine_out   = fine_generator(coarse_out, damaged_inp, expanded_mask_ten)\n",
    "\n",
    "        # (6-7) 원본마스크 영역만 복원(나머지는 원본 이미지 유지)\n",
    "        #       => original_mask_ten이 1인 부분만 fine_out을 사용\n",
    "        orig_mask_bc = original_mask_ten.expand_as(inp_tensor)  # (1,3,H,W)\n",
    "        final_result = inp_tensor * (1 - orig_mask_bc) + fine_out * orig_mask_bc\n",
    "\n",
    "        # (6-8) 결과 저장\n",
    "        final_result_pil = T.ToPILImage()(final_result.squeeze(0).cpu())\n",
    "        save_path = os.path.join(output_dir, filename)\n",
    "        final_result_pil.save(save_path)\n",
    "\n",
    "        print(f\"[INFO] {filename} 복원 완료 -> {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imagepro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
